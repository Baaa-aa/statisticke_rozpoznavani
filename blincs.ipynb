{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ad99eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error, r2_score, \n",
    "                             accuracy_score, roc_auc_score, balanced_accuracy_score, f1_score)\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1f8ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "print_limits = {\"tokens\" : 10}\n",
    "prints = {\"tokens\": 0}\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b947284",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8e1e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_smiles(smiles):\n",
    "    \"\"\"\n",
    "    Tokenizes a SMILES string into chemically meaningful units.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of string tokens.\n",
    "    \"\"\"\n",
    "    # This pattern prioritizes:\n",
    "    # 1. Bracketed atoms (e.g., [nH], [Na+]) -> catch complex states first\n",
    "    # 2. Two-letter atoms (Br, Cl) -> catch before single letters match\n",
    "    # 3. Single-letter atoms (B, C, N, O...)\n",
    "    # 4. Special characters (bonds, parens, digits)\n",
    "    pattern =  r\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|H|B|C|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "    \n",
    "    regex = re.compile(pattern)\n",
    "    tokens = [token for token in regex.findall(smiles)]\n",
    "\n",
    "    if DEBUG and prints[\"tokens\"] < print_limits[\"tokens\"]: \n",
    "        print(f\"[Tokenizer] Input: {smiles} -> Tokens: {tokens}\")\n",
    "        prints[\"tokens\"] += 1\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33273fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSpectrumVectorizer:\n",
    "    def __init__(self, max_k=3):\n",
    "        self.max_k = max_k\n",
    "        self.vectorizer = None\n",
    "        self.feature_names = None\n",
    "        self.k_masks = {} # Stores which columns belong to k=1, k=2, etc.\n",
    "\n",
    "    def fit_transform(self, smiles_list):\n",
    "        if DEBUG:\n",
    "            print(f\"\\n--- Starting Vectorization (Max k={self.max_k}) ---\")\n",
    "        \n",
    "        self.vectorizer = CountVectorizer(\n",
    "            tokenizer=tokenize_smiles,\n",
    "            token_pattern=None, \n",
    "            ngram_range=(1, self.max_k),\n",
    "            lowercase=False,\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        X_sparse = self.vectorizer.fit_transform(smiles_list)\n",
    "        \n",
    "        self.feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "        if DEBUG:\n",
    "            print(f\"[Vectorizer] Total unique substrings found: {len(self.feature_names)}\")\n",
    "            print(f\"[Vectorizer] First 10 features: {self.feature_names[:10]}\")\n",
    "            print(\"[Vectorizer] Creating k-masks for distance metric...\")\n",
    "        \n",
    "        k_counts = np.array([name.count(' ') + 1 for name in self.feature_names])\n",
    "        \n",
    "        for k in range(1, self.max_k + 1):\n",
    "            # Create a boolean array: True if column belongs to k\n",
    "            self.k_masks[k] = (k_counts == k)\n",
    "            \n",
    "            if DEBUG:\n",
    "                count = np.sum(self.k_masks[k])\n",
    "                print(f\"  > Found {count} unique substrings of length k={k}\")\n",
    "\n",
    "        return X_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43f13332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_distance_function(k_masks):\n",
    "    def dist_func(x_vec, y_vec):\n",
    "        if hasattr(x_vec, \"toarray\"): x_vec = x_vec.toarray().flatten()\n",
    "        if hasattr(y_vec, \"toarray\"): y_vec = y_vec.toarray().flatten()\n",
    "        \n",
    "        diff = np.abs(x_vec - y_vec)\n",
    "        total_sq_dist = 0.0\n",
    "        \n",
    "        for k, mask in k_masks.items():\n",
    "            d_k = np.sum(diff[mask])\n",
    "            total_sq_dist += d_k ** 2\n",
    "            \n",
    "        return np.sqrt(total_sq_dist)\n",
    "    return dist_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d86f66",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "456bb223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(experiment_name, model, param_grid, X_train, X_test, y_train, y_test, mode='regression'):\n",
    "    \"\"\"\n",
    "    Runs a GridSearch experiment, evaluates on test set, and updates the global results dataframe.\n",
    "    \"\"\"\n",
    "    global df_regression, df_classification\n",
    "    \n",
    "    print(f\"--- Running Experiment: {experiment_name} ({mode}) ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 1. Grid Search to find best parameters\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error' if mode == 'regression' else 'accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "    \n",
    "    # 2. Prediction on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # 3. Calculate metrics\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    if mode == 'regression':\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        new_row = pd.DataFrame([{\n",
    "            'experiment': experiment_name,\n",
    "            'best_params': str(best_params),\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'time_s': elapsed_time\n",
    "        }])\n",
    "        if not new_row.empty:\n",
    "             df_regression = pd.concat([df_regression, new_row], ignore_index=True)\n",
    "        \n",
    "        print(f\"  > Best Params: {best_params}\")\n",
    "        print(f\"  > RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "\n",
    "    elif mode == 'classification':\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted') \n",
    "        \n",
    "        try:\n",
    "            if hasattr(best_model, \"predict_proba\"):\n",
    "                if len(np.unique(y_train)) == 2:\n",
    "                    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "                else:\n",
    "                    y_prob = best_model.predict_proba(X_test) # Multiclass\n",
    "                roc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
    "            else:\n",
    "                roc = np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"  ! Could not calc ROC-AUC: {e}\")\n",
    "            roc = np.nan\n",
    "\n",
    "        new_row = pd.DataFrame([{\n",
    "            'experiment': experiment_name,\n",
    "            'best_params': str(best_params),\n",
    "            'accuracy': acc,\n",
    "            'balanced_accuracy': bal_acc,\n",
    "            'f1': f1,\n",
    "            'roc_auc': roc,\n",
    "            'time_s': elapsed_time\n",
    "        }])\n",
    "        \n",
    "        if not new_row.empty:\n",
    "            df_classification = pd.concat([df_classification, new_row], ignore_index=True)\n",
    "        \n",
    "        print(f\"  > Best Params: {best_params}\")\n",
    "        print(f\"  > Acc: {acc:.4f} | ROC-AUC: {roc:.4f}\")\n",
    "\n",
    "    print(f\"  > Time: {elapsed_time:.2f}s\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "142c76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_results(df, mode='regression'):\n",
    "    \"\"\"\n",
    "    Applies green (best) and red (worst) highlighting to a results dataframe.\n",
    "    \"\"\"\n",
    "    styled = df.copy().style.format(precision=4)\n",
    "    \n",
    "    best_style = 'background-color: #d4edda; color: #155724; font-weight: bold;' # Green\n",
    "    worst_style = 'background-color: #f8d7da; color: #721c24;' # Red\n",
    "    \n",
    "    def highlight_col(s, higher_is_better=True):\n",
    "        is_best = s == s.max() if higher_is_better else s == s.min()\n",
    "        is_worst = s == s.min() if higher_is_better else s == s.max()\n",
    "        \n",
    "        return [best_style if b else worst_style if w else '' \n",
    "                for b, w in zip(is_best, is_worst)]\n",
    "\n",
    "    # Apply based on mode\n",
    "    if mode == 'regression':\n",
    "        styled = styled.apply(highlight_col, subset=['mae', 'rmse'], higher_is_better=False)\n",
    "        styled = styled.apply(highlight_col, subset=['r2'], higher_is_better=True)\n",
    "        \n",
    "    elif mode == 'classification':\n",
    "        metrics = ['accuracy', 'balanced_accuracy', 'f1', 'roc_auc']\n",
    "        existing_metrics = [m for m in metrics if m in df.columns]\n",
    "        \n",
    "        styled = styled.apply(highlight_col, subset=existing_metrics, higher_is_better=True)\n",
    "\n",
    "    return styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c36e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression = pd.DataFrame(columns=[\n",
    "    'experiment', 'best_params', 'mae', 'rmse', 'r2', 'time_s'\n",
    "])\n",
    "df_classification = pd.DataFrame(columns=[\n",
    "    'experiment', 'best_params', 'accuracy', 'balanced_accuracy', 'f1', 'roc_auc', 'time_s'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1018ee",
   "metadata": {},
   "source": [
    "## ESOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3dd4dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('esol.csv')\n",
    "col_smiles = 'smiles'\n",
    "col_target = 'measured log solubility in mols per litre'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75302cf6",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9b09d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-calculating features for max_k=5...\n",
      "--- Running Experiment: KNN (max_k=1) (regression) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baaa\\AppData\\Local\\Temp\\ipykernel_14760\\3153140418.py:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_regression = pd.concat([df_regression, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Best Params: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "  > RMSE: 0.8092 | R2: 0.8565\n",
      "  > Time: 78.74s\n",
      "\n",
      "--- Running Experiment: KNN (max_k=2) (regression) ---\n",
      "  > Best Params: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "  > RMSE: 0.8587 | R2: 0.8383\n",
      "  > Time: 82.34s\n",
      "\n",
      "--- Running Experiment: KNN (max_k=3) (regression) ---\n",
      "  > Best Params: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "  > RMSE: 0.9534 | R2: 0.8007\n",
      "  > Time: 91.31s\n",
      "\n",
      "--- Running Experiment: KNN (max_k=4) (regression) ---\n",
      "  > Best Params: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "  > RMSE: 1.0772 | R2: 0.7456\n",
      "  > Time: 110.43s\n",
      "\n",
      "--- Running Experiment: KNN (max_k=5) (regression) ---\n",
      "  > Best Params: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "  > RMSE: 1.2188 | R2: 0.6743\n",
      "  > Time: 122.39s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "largest_k = 5\n",
    "print(f\"Pre-calculating features for max_k={largest_k}...\")\n",
    "\n",
    "# Initialize vectorizer with the absolute maximum k\n",
    "global_vectorizer = KSpectrumVectorizer(max_k=largest_k)\n",
    "X_all = global_vectorizer.fit_transform(df[col_smiles].astype(str).tolist())\n",
    "y_all = df[col_target].values\n",
    "global_masks = global_vectorizer.k_masks\n",
    "\n",
    "# Train/test split fixed for all experiments\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.3, random_state=random_seed\n",
    ")\n",
    "\n",
    "k_values_to_test = [1, 2, 3, 4, 5]\n",
    "\n",
    "for k in k_values_to_test:\n",
    "    \n",
    "    # Create a subset of masks that only contains keys 1..k\n",
    "    subset_masks = {i: global_masks[i] for i in range(1, k + 1)}\n",
    "    \n",
    "    # Create a metric that only sees the columns relevant to this k\n",
    "    current_metric = make_distance_function(subset_masks)\n",
    "    \n",
    "    knn_custom = KNeighborsRegressor(\n",
    "        metric=current_metric, \n",
    "        algorithm='brute',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    params_knn = {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    }\n",
    "    \n",
    "    # Run using the shared X_train/X_test\n",
    "    # Note: X_train has columns for k > current k_max, but the metric will ignore them \n",
    "\n",
    "    run_experiment(\n",
    "        f\"KNN (max_k={k})\", \n",
    "        knn_custom, \n",
    "        params_knn, \n",
    "        X_train, X_test, y_train, y_test, \n",
    "        mode='regression'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669ecad",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c06836d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-calculating features for max_k=5...\n",
      "--- Running Experiment: Random Forest (All Features) (regression) ---\n",
      "  > Best Params: {'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 200}\n",
      "  > RMSE: 0.8357 | R2: 0.8469\n",
      "  > Time: 135.60s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "largest_k = 5\n",
    "print(f\"Pre-calculating features for max_k={largest_k}...\")\n",
    "\n",
    "# Initialize vectorizer with the absolute maximum k\n",
    "global_vectorizer = KSpectrumVectorizer(max_k=largest_k)\n",
    "X_all = global_vectorizer.fit_transform(df[col_smiles].astype(str).tolist())\n",
    "y_all = df[col_target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.3, random_state=random_seed\n",
    ")\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=random_seed, n_jobs=-1)\n",
    "\n",
    "params_rf = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300],      # Number of trees\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "run_experiment(\n",
    "    \"Random Forest (All Features)\", \n",
    "    rf_model, \n",
    "    params_rf, \n",
    "    X_train, X_test, y_train, y_test, \n",
    "    mode='regression'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1dbfb5",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4404c1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-calculating features for max_k=5...\n",
      "--- Running Experiment: KRR (max_k=1) (regression) ---\n",
      "  > Best Params: {'alpha': 10, 'gamma': 0.001}\n",
      "  > RMSE: 1.6181 | R2: 0.4259\n",
      "  > Time: 223.98s\n",
      "\n",
      "--- Running Experiment: KRR (max_k=2) (regression) ---\n",
      "  > Best Params: {'alpha': 10, 'gamma': 0.001}\n",
      "  > RMSE: 1.8411 | R2: 0.2568\n",
      "  > Time: 244.11s\n",
      "\n",
      "--- Running Experiment: KRR (max_k=3) (regression) ---\n",
      "  > Best Params: {'alpha': 10, 'gamma': 0.001}\n",
      "  > RMSE: 2.4089 | R2: -0.2723\n",
      "  > Time: 264.14s\n",
      "\n",
      "--- Running Experiment: KRR (max_k=4) (regression) ---\n",
      "  > Best Params: {'alpha': 10, 'gamma': 0.001}\n",
      "  > RMSE: 2.8777 | R2: -0.8157\n",
      "  > Time: 299.29s\n",
      "\n",
      "--- Running Experiment: KRR (max_k=5) (regression) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Baaa\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:252: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Best Params: {'alpha': 1.0, 'gamma': 0.001}\n",
      "  > RMSE: 2.9188 | R2: -0.8679\n",
      "  > Time: 338.91s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wrapper class, scikit does not defaultly support custom distance functions in Kernel Ridge Regression\n",
    "class KSpectrumKRR(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, k_masks=None, alpha=1.0, gamma=0.1):\n",
    "        self.k_masks = k_masks\n",
    "        self.alpha = alpha  # Regularization strength\n",
    "        self.gamma = gamma  # Kernel width (1/sigma^2)\n",
    "        self.model = None\n",
    "        self.X_train_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train_ = X\n",
    "        \n",
    "        # 1. Create the distance function\n",
    "        dist_func = make_distance_function(self.k_masks)\n",
    "        \n",
    "        # 2. Compute distance matrix (Train vs Train)\n",
    "        D = pairwise_distances(X, metric=dist_func)\n",
    "        \n",
    "        # 3. Convert distance to kernel\n",
    "        # K = exp(-gamma * distance^2)\n",
    "        K = np.exp(-self.gamma * D**2)\n",
    "        \n",
    "        # 4. Fit standard kernel ridge with precomputed kernel\n",
    "        self.model = KernelRidge(alpha=self.alpha, kernel='precomputed')\n",
    "        self.model.fit(K, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        dist_func = make_distance_function(self.k_masks)\n",
    "        \n",
    "        D_test = pairwise_distances(X, self.X_train_, metric=dist_func)\n",
    "        \n",
    "        K_test = np.exp(-self.gamma * D_test**2)\n",
    "        \n",
    "        return self.model.predict(K_test)\n",
    "\n",
    "\n",
    "largest_k = 5\n",
    "print(f\"Pre-calculating features for max_k={largest_k}...\")\n",
    "\n",
    "global_vectorizer = KSpectrumVectorizer(max_k=largest_k)\n",
    "X_all = global_vectorizer.fit_transform(df[col_smiles].astype(str).tolist())\n",
    "y_all = df[col_target].values\n",
    "global_masks = global_vectorizer.k_masks\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.3, random_state=random_seed\n",
    ")\n",
    "\n",
    "k_values_to_test = [1, 2, 3, 4, 5]\n",
    "\n",
    "for k in k_values_to_test:\n",
    "    \n",
    "    subset_masks = {i: global_masks[i] for i in range(1, k + 1)}\n",
    "    \n",
    "    krr_custom = KSpectrumKRR(k_masks=subset_masks)\n",
    "    \n",
    "    # Parameter Grid\n",
    "    # Alpha: Higher = more regularization (prevents overfitting)\n",
    "    # Gamma: Higher = similarity drops off faster (only very close molecules matter)\n",
    "    params_krr = {\n",
    "        'alpha': [1e-3, 0.1, 1.0, 10],\n",
    "        'gamma': [0.001, 0.01, 0.1, 0.5] \n",
    "    }\n",
    "    \n",
    "    run_experiment(\n",
    "        f\"KRR (max_k={k})\", \n",
    "        krr_custom, \n",
    "        params_krr, \n",
    "        X_train, X_test, y_train, y_test, \n",
    "        mode='regression'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5991a9f",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ca8a650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_19892_row0_col2, #T_19892_row0_col3, #T_19892_row0_col4 {\n",
       "  background-color: #d4edda;\n",
       "  color: #155724;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_19892_row11_col2, #T_19892_row12_col3, #T_19892_row12_col4 {\n",
       "  background-color: #f8d7da;\n",
       "  color: #721c24;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_19892\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_19892_level0_col0\" class=\"col_heading level0 col0\" >experiment</th>\n",
       "      <th id=\"T_19892_level0_col1\" class=\"col_heading level0 col1\" >best_params</th>\n",
       "      <th id=\"T_19892_level0_col2\" class=\"col_heading level0 col2\" >mae</th>\n",
       "      <th id=\"T_19892_level0_col3\" class=\"col_heading level0 col3\" >rmse</th>\n",
       "      <th id=\"T_19892_level0_col4\" class=\"col_heading level0 col4\" >r2</th>\n",
       "      <th id=\"T_19892_level0_col5\" class=\"col_heading level0 col5\" >time_s</th>\n",
       "      <th id=\"T_19892_level0_col6\" class=\"col_heading level0 col6\" >dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_19892_row0_col0\" class=\"data row0 col0\" >KNN (max_k=1)</td>\n",
       "      <td id=\"T_19892_row0_col1\" class=\"data row0 col1\" >{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td id=\"T_19892_row0_col2\" class=\"data row0 col2\" >0.5991</td>\n",
       "      <td id=\"T_19892_row0_col3\" class=\"data row0 col3\" >0.8092</td>\n",
       "      <td id=\"T_19892_row0_col4\" class=\"data row0 col4\" >0.8565</td>\n",
       "      <td id=\"T_19892_row0_col5\" class=\"data row0 col5\" >78.7351</td>\n",
       "      <td id=\"T_19892_row0_col6\" class=\"data row0 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_19892_row1_col0\" class=\"data row1 col0\" >KNN (max_k=2)</td>\n",
       "      <td id=\"T_19892_row1_col1\" class=\"data row1 col1\" >{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td id=\"T_19892_row1_col2\" class=\"data row1 col2\" >0.6300</td>\n",
       "      <td id=\"T_19892_row1_col3\" class=\"data row1 col3\" >0.8587</td>\n",
       "      <td id=\"T_19892_row1_col4\" class=\"data row1 col4\" >0.8383</td>\n",
       "      <td id=\"T_19892_row1_col5\" class=\"data row1 col5\" >82.3384</td>\n",
       "      <td id=\"T_19892_row1_col6\" class=\"data row1 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_19892_row2_col0\" class=\"data row2 col0\" >KNN (max_k=3)</td>\n",
       "      <td id=\"T_19892_row2_col1\" class=\"data row2 col1\" >{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td id=\"T_19892_row2_col2\" class=\"data row2 col2\" >0.7074</td>\n",
       "      <td id=\"T_19892_row2_col3\" class=\"data row2 col3\" >0.9534</td>\n",
       "      <td id=\"T_19892_row2_col4\" class=\"data row2 col4\" >0.8007</td>\n",
       "      <td id=\"T_19892_row2_col5\" class=\"data row2 col5\" >91.3117</td>\n",
       "      <td id=\"T_19892_row2_col6\" class=\"data row2 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_19892_row3_col0\" class=\"data row3 col0\" >KNN (max_k=4)</td>\n",
       "      <td id=\"T_19892_row3_col1\" class=\"data row3 col1\" >{'n_neighbors': 3, 'weights': 'distance'}</td>\n",
       "      <td id=\"T_19892_row3_col2\" class=\"data row3 col2\" >0.7717</td>\n",
       "      <td id=\"T_19892_row3_col3\" class=\"data row3 col3\" >1.0772</td>\n",
       "      <td id=\"T_19892_row3_col4\" class=\"data row3 col4\" >0.7456</td>\n",
       "      <td id=\"T_19892_row3_col5\" class=\"data row3 col5\" >110.4308</td>\n",
       "      <td id=\"T_19892_row3_col6\" class=\"data row3 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_19892_row4_col0\" class=\"data row4 col0\" >KNN (max_k=5)</td>\n",
       "      <td id=\"T_19892_row4_col1\" class=\"data row4 col1\" >{'n_neighbors': 3, 'weights': 'distance'}</td>\n",
       "      <td id=\"T_19892_row4_col2\" class=\"data row4 col2\" >0.8582</td>\n",
       "      <td id=\"T_19892_row4_col3\" class=\"data row4 col3\" >1.2188</td>\n",
       "      <td id=\"T_19892_row4_col4\" class=\"data row4 col4\" >0.6743</td>\n",
       "      <td id=\"T_19892_row4_col5\" class=\"data row4 col5\" >122.3921</td>\n",
       "      <td id=\"T_19892_row4_col6\" class=\"data row4 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_19892_row5_col0\" class=\"data row5 col0\" >Random Forest (All Features)</td>\n",
       "      <td id=\"T_19892_row5_col1\" class=\"data row5 col1\" >{'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 200}</td>\n",
       "      <td id=\"T_19892_row5_col2\" class=\"data row5 col2\" >0.6172</td>\n",
       "      <td id=\"T_19892_row5_col3\" class=\"data row5 col3\" >0.8357</td>\n",
       "      <td id=\"T_19892_row5_col4\" class=\"data row5 col4\" >0.8469</td>\n",
       "      <td id=\"T_19892_row5_col5\" class=\"data row5 col5\" >67.7005</td>\n",
       "      <td id=\"T_19892_row5_col6\" class=\"data row5 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_19892_row6_col0\" class=\"data row6 col0\" >Random Forest (All Features)</td>\n",
       "      <td id=\"T_19892_row6_col1\" class=\"data row6 col1\" >{'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 200}</td>\n",
       "      <td id=\"T_19892_row6_col2\" class=\"data row6 col2\" >0.6172</td>\n",
       "      <td id=\"T_19892_row6_col3\" class=\"data row6 col3\" >0.8357</td>\n",
       "      <td id=\"T_19892_row6_col4\" class=\"data row6 col4\" >0.8469</td>\n",
       "      <td id=\"T_19892_row6_col5\" class=\"data row6 col5\" >135.6017</td>\n",
       "      <td id=\"T_19892_row6_col6\" class=\"data row6 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_19892_row7_col0\" class=\"data row7 col0\" >KRR (max_k=1)</td>\n",
       "      <td id=\"T_19892_row7_col1\" class=\"data row7 col1\" >{'alpha': 1.0, 'gamma': 0.1}</td>\n",
       "      <td id=\"T_19892_row7_col2\" class=\"data row7 col2\" >1.6273</td>\n",
       "      <td id=\"T_19892_row7_col3\" class=\"data row7 col3\" >2.3566</td>\n",
       "      <td id=\"T_19892_row7_col4\" class=\"data row7 col4\" >-0.2176</td>\n",
       "      <td id=\"T_19892_row7_col5\" class=\"data row7 col5\" >146.2699</td>\n",
       "      <td id=\"T_19892_row7_col6\" class=\"data row7 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_19892_row8_col0\" class=\"data row8 col0\" >KRR (max_k=1)</td>\n",
       "      <td id=\"T_19892_row8_col1\" class=\"data row8 col1\" >{'alpha': 10, 'gamma': 0.001}</td>\n",
       "      <td id=\"T_19892_row8_col2\" class=\"data row8 col2\" >1.2477</td>\n",
       "      <td id=\"T_19892_row8_col3\" class=\"data row8 col3\" >1.6181</td>\n",
       "      <td id=\"T_19892_row8_col4\" class=\"data row8 col4\" >0.4259</td>\n",
       "      <td id=\"T_19892_row8_col5\" class=\"data row8 col5\" >223.9843</td>\n",
       "      <td id=\"T_19892_row8_col6\" class=\"data row8 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_19892_row9_col0\" class=\"data row9 col0\" >KRR (max_k=2)</td>\n",
       "      <td id=\"T_19892_row9_col1\" class=\"data row9 col1\" >{'alpha': 10, 'gamma': 0.001}</td>\n",
       "      <td id=\"T_19892_row9_col2\" class=\"data row9 col2\" >1.3820</td>\n",
       "      <td id=\"T_19892_row9_col3\" class=\"data row9 col3\" >1.8411</td>\n",
       "      <td id=\"T_19892_row9_col4\" class=\"data row9 col4\" >0.2568</td>\n",
       "      <td id=\"T_19892_row9_col5\" class=\"data row9 col5\" >244.1093</td>\n",
       "      <td id=\"T_19892_row9_col6\" class=\"data row9 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_19892_row10_col0\" class=\"data row10 col0\" >KRR (max_k=3)</td>\n",
       "      <td id=\"T_19892_row10_col1\" class=\"data row10 col1\" >{'alpha': 10, 'gamma': 0.001}</td>\n",
       "      <td id=\"T_19892_row10_col2\" class=\"data row10 col2\" >1.8491</td>\n",
       "      <td id=\"T_19892_row10_col3\" class=\"data row10 col3\" >2.4089</td>\n",
       "      <td id=\"T_19892_row10_col4\" class=\"data row10 col4\" >-0.2723</td>\n",
       "      <td id=\"T_19892_row10_col5\" class=\"data row10 col5\" >264.1424</td>\n",
       "      <td id=\"T_19892_row10_col6\" class=\"data row10 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_19892_row11_col0\" class=\"data row11 col0\" >KRR (max_k=4)</td>\n",
       "      <td id=\"T_19892_row11_col1\" class=\"data row11 col1\" >{'alpha': 10, 'gamma': 0.001}</td>\n",
       "      <td id=\"T_19892_row11_col2\" class=\"data row11 col2\" >2.2642</td>\n",
       "      <td id=\"T_19892_row11_col3\" class=\"data row11 col3\" >2.8777</td>\n",
       "      <td id=\"T_19892_row11_col4\" class=\"data row11 col4\" >-0.8157</td>\n",
       "      <td id=\"T_19892_row11_col5\" class=\"data row11 col5\" >299.2948</td>\n",
       "      <td id=\"T_19892_row11_col6\" class=\"data row11 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19892_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_19892_row12_col0\" class=\"data row12 col0\" >KRR (max_k=5)</td>\n",
       "      <td id=\"T_19892_row12_col1\" class=\"data row12 col1\" >{'alpha': 1.0, 'gamma': 0.001}</td>\n",
       "      <td id=\"T_19892_row12_col2\" class=\"data row12 col2\" >2.2314</td>\n",
       "      <td id=\"T_19892_row12_col3\" class=\"data row12 col3\" >2.9188</td>\n",
       "      <td id=\"T_19892_row12_col4\" class=\"data row12 col4\" >-0.8679</td>\n",
       "      <td id=\"T_19892_row12_col5\" class=\"data row12 col5\" >338.9134</td>\n",
       "      <td id=\"T_19892_row12_col6\" class=\"data row12 col6\" >ESOL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26fcfa4c560>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Regression Results:\")\n",
    "display(style_results(df_regression, mode='regression'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7869ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression[\"dataset\"] = \"ESOL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cbbfade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression.to_csv('regression_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda31e4",
   "metadata": {},
   "source": [
    "## BACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0fec3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bace = pd.read_csv('bace.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "daa966b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n",
      "Test     1265\n",
      "Train     203\n",
      "Valid      45\n",
      "Name: count, dtype: int64\n",
      "      Non-Inhibitor (0) Inhibitor (1)\n",
      "Model                                \n",
      "Test             56.84%        43.16%\n",
      "Train            50.25%        49.75%\n",
      "Valid             2.22%        97.78%\n",
      "\n",
      "Warning: Found 45 rows with unknown split labels!\n",
      "['Valid']\n"
     ]
    }
   ],
   "source": [
    "split_counts = df_bace['Model'].value_counts()\n",
    "print(split_counts)\n",
    "balance = df_bace.groupby('Model')['Class'].value_counts(normalize=True).unstack() * 100\n",
    "balance.columns = ['Non-Inhibitor (0)', 'Inhibitor (1)']\n",
    "print(balance.round(2).astype(str) + '%')\n",
    "\n",
    "unknown_splits = df_bace[~df_bace['Model'].isin(['Train', 'Test', 'train', 'test'])]\n",
    "if not unknown_splits.empty:\n",
    "    print(f\"\\nWarning: Found {len(unknown_splits)} rows with unknown split labels!\")\n",
    "    print(unknown_splits['Model'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5343fbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset size: 1468\n",
      "Assigning 'Test' (1265 rows) as TRAINING set.\n",
      "Assigning 'Train' (203 rows) as TEST set.\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_bace[df_bace['Model'].isin(['Train', 'Test'])].copy()\n",
    "\n",
    "col_smiles = 'mol'\n",
    "col_target = 'Class'\n",
    "\n",
    "print(f\"Cleaned dataset size: {len(df_clean)}\")\n",
    "\n",
    "# Auto-assign Train/Test based on which label has more rows (the dataset seems to have swapped labels)\n",
    "counts = df_clean['Model'].value_counts()\n",
    "label_large = counts.idxmax()\n",
    "label_small = counts.idxmin()\n",
    "\n",
    "print(f\"Assigning '{label_large}' ({counts[label_large]} rows) as TRAINING set.\")\n",
    "print(f\"Assigning '{label_small}' ({counts[label_small]} rows) as TEST set.\")\n",
    "\n",
    "# Create masks based on size, not name\n",
    "train_mask = (df_clean['Model'] == label_large).values\n",
    "test_mask = (df_clean['Model'] == label_small).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c233a57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectorizing features for max_k=5...\n"
     ]
    }
   ],
   "source": [
    "largest_k = 5\n",
    "print(f\"\\nVectorizing features for max_k={largest_k}...\")\n",
    "\n",
    "global_vectorizer = KSpectrumVectorizer(max_k=largest_k)\n",
    "X_all = global_vectorizer.fit_transform(df_clean[col_smiles].astype(str).tolist())\n",
    "y_all = df_clean[col_target].values\n",
    "global_masks = global_vectorizer.k_masks\n",
    "\n",
    "# Apply the corrected masks\n",
    "X_train = X_all[train_mask]\n",
    "y_train = y_all[train_mask]\n",
    "\n",
    "X_test = X_all[test_mask]\n",
    "y_test = y_all[test_mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374baab",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "608a6650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Experiment: KNN-Clf (Scaffold, k=1) (classification) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baaa\\AppData\\Local\\Temp\\ipykernel_14760\\3153140418.py:77: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_classification = pd.concat([df_classification, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Best Params: {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "  > Acc: 0.7094 | ROC-AUC: 0.7672\n",
      "  > Time: 153.85s\n",
      "\n",
      "--- Running Experiment: KNN-Clf (Scaffold, k=2) (classification) ---\n",
      "  > Best Params: {'n_neighbors': 9, 'weights': 'distance'}\n",
      "  > Acc: 0.7094 | ROC-AUC: 0.8025\n",
      "  > Time: 171.20s\n",
      "\n",
      "--- Running Experiment: KNN-Clf (Scaffold, k=3) (classification) ---\n",
      "  > Best Params: {'n_neighbors': 9, 'weights': 'distance'}\n",
      "  > Acc: 0.6847 | ROC-AUC: 0.8001\n",
      "  > Time: 179.73s\n",
      "\n",
      "--- Running Experiment: KNN-Clf (Scaffold, k=4) (classification) ---\n",
      "  > Best Params: {'n_neighbors': 15, 'weights': 'distance'}\n",
      "  > Acc: 0.6946 | ROC-AUC: 0.8137\n",
      "  > Time: 202.72s\n",
      "\n",
      "--- Running Experiment: KNN-Clf (Scaffold, k=5) (classification) ---\n",
      "  > Best Params: {'n_neighbors': 15, 'weights': 'distance'}\n",
      "  > Acc: 0.6995 | ROC-AUC: 0.8138\n",
      "  > Time: 236.93s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_values_to_test = [1, 2, 3, 4, 5]\n",
    "\n",
    "for k in k_values_to_test:\n",
    "    \n",
    "    subset_masks = {i: global_masks[i] for i in range(1, k + 1)}\n",
    "    \n",
    "    current_metric = make_distance_function(subset_masks)\n",
    "    \n",
    "    knn_clf = KNeighborsClassifier(\n",
    "        metric=current_metric,\n",
    "        algorithm='brute',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    params_knn = {\n",
    "        'n_neighbors': [3, 5, 9, 15],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    }\n",
    "    \n",
    "    run_experiment(\n",
    "        f\"KNN-Clf (Scaffold, k={k})\", \n",
    "        knn_clf, \n",
    "        params_knn, \n",
    "        X_train, X_test, y_train, y_test, \n",
    "        mode='classification'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe39812",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f547a3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Experiment: Random Forest (Scaffold) (classification) ---\n",
      "  > Best Params: {'max_depth': None, 'min_samples_leaf': 4, 'n_estimators': 100}\n",
      "  > Acc: 0.6601 | ROC-AUC: 0.8531\n",
      "  > Time: 4.37s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=random_seed, n_jobs=-1)\n",
    "\n",
    "params_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "run_experiment(\n",
    "    \"Random Forest (Scaffold)\", \n",
    "    rf_clf, \n",
    "    params_rf, \n",
    "    X_train, X_test, y_train, y_test, \n",
    "    mode='classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b9afb",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f99375a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper for SVC with custom kernel\n",
    "class KSpectrumSVC(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, k_masks=None, C=1.0, gamma=0.1):\n",
    "        self.k_masks = k_masks\n",
    "        self.C = C          # Regularization (Lower = more regularization)\n",
    "        self.gamma = gamma  # Kernel width\n",
    "        self.model = None\n",
    "        self.X_train_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train_ = X\n",
    "        \n",
    "        # 1. Calculate custom distance matrix (Train vs Train)\n",
    "        dist_func = make_distance_function(self.k_masks)\n",
    "        D_train = pairwise_distances(X, metric=dist_func)\n",
    "        \n",
    "        # 2. Convert to RBF kernel: K = exp(-gamma * distance^2)\n",
    "        K_train = np.exp(-self.gamma * D_train**2)\n",
    "        \n",
    "        # 3. Fit standard SVC with precomputed kernel\n",
    "        self.model = SVC(C=self.C, kernel='precomputed', probability=True, random_state=42)\n",
    "        self.model.fit(K_train, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Calculate distance (Test vs Train)\n",
    "        dist_func = make_distance_function(self.k_masks)\n",
    "        D_test = pairwise_distances(X, self.X_train_, metric=dist_func)\n",
    "        \n",
    "        # Convert to kernel\n",
    "        K_test = np.exp(-self.gamma * D_test**2)\n",
    "        return self.model.predict(K_test)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Calculate distance (Test vs Train)\n",
    "        dist_func = make_distance_function(self.k_masks)\n",
    "        D_test = pairwise_distances(X, self.X_train_, metric=dist_func)\n",
    "        \n",
    "        # Convert to kernel\n",
    "        K_test = np.exp(-self.gamma * D_test**2)\n",
    "        return self.model.predict_proba(K_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4572a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values_to_test = [1, 3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f392b93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Experiment: SVM-Clf (Scaffold, k=1) (classification) ---\n",
      "  > Best Params: {'C': 10, 'gamma': 0.1}\n",
      "  > Acc: 0.5616 | ROC-AUC: 0.6788\n",
      "  > Time: 346.61s\n",
      "\n",
      "--- Running Experiment: SVM-Clf (Scaffold, k=3) (classification) ---\n",
      "  > Best Params: {'C': 10, 'gamma': 0.001}\n",
      "  > Acc: 0.6207 | ROC-AUC: 0.7599\n",
      "  > Time: 416.70s\n",
      "\n",
      "--- Running Experiment: SVM-Clf (Scaffold, k=5) (classification) ---\n",
      "  > Best Params: {'C': 10, 'gamma': 0.001}\n",
      "  > Acc: 0.5714 | ROC-AUC: 0.7595\n",
      "  > Time: 551.79s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in k_values_to_test:\n",
    "    \n",
    "    subset_masks = {i: global_masks[i] for i in range(1, k + 1)}\n",
    "    \n",
    "    svc_custom = KSpectrumSVC(k_masks=subset_masks)\n",
    "    \n",
    "    params_svc = {\n",
    "        'C': [1, 10, 100],\n",
    "        'gamma': [0.001, 0.01, 0.1]\n",
    "    }\n",
    "    \n",
    "    run_experiment(\n",
    "        f\"SVM-Clf (Scaffold, k={k})\", \n",
    "        svc_custom, \n",
    "        params_svc, \n",
    "        X_train, X_test, y_train, y_test, \n",
    "        mode='classification'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87be2bff",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cde3bd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BACE Classification Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_740b5_row0_col2, #T_740b5_row0_col3, #T_740b5_row0_col4, #T_740b5_row1_col2, #T_740b5_row5_col5 {\n",
       "  background-color: #d4edda;\n",
       "  color: #155724;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_740b5_row6_col2, #T_740b5_row6_col3, #T_740b5_row6_col4, #T_740b5_row6_col5 {\n",
       "  background-color: #f8d7da;\n",
       "  color: #721c24;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_740b5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_740b5_level0_col0\" class=\"col_heading level0 col0\" >experiment</th>\n",
       "      <th id=\"T_740b5_level0_col1\" class=\"col_heading level0 col1\" >best_params</th>\n",
       "      <th id=\"T_740b5_level0_col2\" class=\"col_heading level0 col2\" >accuracy</th>\n",
       "      <th id=\"T_740b5_level0_col3\" class=\"col_heading level0 col3\" >balanced_accuracy</th>\n",
       "      <th id=\"T_740b5_level0_col4\" class=\"col_heading level0 col4\" >f1</th>\n",
       "      <th id=\"T_740b5_level0_col5\" class=\"col_heading level0 col5\" >roc_auc</th>\n",
       "      <th id=\"T_740b5_level0_col6\" class=\"col_heading level0 col6\" >time_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_740b5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_740b5_row0_col0\" class=\"data row0 col0\" >KNN-Clf (Scaffold, k=1)</td>\n",
       "      <td id=\"T_740b5_row0_col1\" class=\"data row0 col1\" >{'n_neighbors': 3, 'weights': 'uniform'}</td>\n",
       "      <td id=\"T_740b5_row0_col2\" class=\"data row0 col2\" >0.7094</td>\n",
       "      <td id=\"T_740b5_row0_col3\" class=\"data row0 col3\" >0.7088</td>\n",
       "      <td id=\"T_740b5_row0_col4\" class=\"data row0 col4\" >0.7054</td>\n",
       "      <td id=\"T_740b5_row0_col5\" class=\"data row0 col5\" >0.7672</td>\n",
       "      <td id=\"T_740b5_row0_col6\" class=\"data row0 col6\" >153.8463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_740b5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_740b5_row1_col0\" class=\"data row1 col0\" >KNN-Clf (Scaffold, k=2)</td>\n",
       "      <td id=\"T_740b5_row1_col1\" class=\"data row1 col1\" >{'n_neighbors': 9, 'weights': 'distance'}</td>\n",
       "      <td id=\"T_740b5_row1_col2\" class=\"data row1 col2\" >0.7094</td>\n",
       "      <td id=\"T_740b5_row1_col3\" class=\"data row1 col3\" >0.7084</td>\n",
       "      <td id=\"T_740b5_row1_col4\" class=\"data row1 col4\" >0.6967</td>\n",
       "      <td id=\"T_740b5_row1_col5\" class=\"data row1 col5\" >0.8025</td>\n",
       "      <td id=\"T_740b5_row1_col6\" class=\"data row1 col6\" >171.2043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_740b5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_740b5_row2_col0\" class=\"data row2 col0\" >KNN-Clf (Scaffold, k=3)</td>\n",
       "      <td id=\"T_740b5_row2_col1\" class=\"data row2 col1\" >{'n_neighbors': 9, 'weights': 'distance'}</td>\n",
       "      <td id=\"T_740b5_row2_col2\" class=\"data row2 col2\" >0.6847</td>\n",
       "      <td id=\"T_740b5_row2_col3\" class=\"data row2 col3\" >0.6837</td>\n",
       "      <td id=\"T_740b5_row2_col4\" class=\"data row2 col4\" >0.6703</td>\n",
       "      <td id=\"T_740b5_row2_col5\" class=\"data row2 col5\" >0.8001</td>\n",
       "      <td id=\"T_740b5_row2_col6\" class=\"data row2 col6\" >179.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_740b5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_740b5_row3_col0\" class=\"data row3 col0\" >KNN-Clf (Scaffold, k=4)</td>\n",
       "      <td id=\"T_740b5_row3_col1\" class=\"data row3 col1\" >{'n_neighbors': 15, 'weights': 'distance'}</td>\n",
       "      <td id=\"T_740b5_row3_col2\" class=\"data row3 col2\" >0.6946</td>\n",
       "      <td id=\"T_740b5_row3_col3\" class=\"data row3 col3\" >0.6936</td>\n",
       "      <td id=\"T_740b5_row3_col4\" class=\"data row3 col4\" >0.6806</td>\n",
       "      <td id=\"T_740b5_row3_col5\" class=\"data row3 col5\" >0.8137</td>\n",
       "      <td id=\"T_740b5_row3_col6\" class=\"data row3 col6\" >202.7241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_740b5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_740b5_row4_col0\" class=\"data row4 col0\" >KNN-Clf (Scaffold, k=5)</td>\n",
       "      <td id=\"T_740b5_row4_col1\" class=\"data row4 col1\" >{'n_neighbors': 15, 'weights': 'distance'}</td>\n",
       "      <td id=\"T_740b5_row4_col2\" class=\"data row4 col2\" >0.6995</td>\n",
       "      <td id=\"T_740b5_row4_col3\" class=\"data row4 col3\" >0.6985</td>\n",
       "      <td id=\"T_740b5_row4_col4\" class=\"data row4 col4\" >0.6850</td>\n",
       "      <td id=\"T_740b5_row4_col5\" class=\"data row4 col5\" >0.8138</td>\n",
       "      <td id=\"T_740b5_row4_col6\" class=\"data row4 col6\" >236.9298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_740b5_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_740b5_row5_col0\" class=\"data row5 col0\" >Random Forest (Scaffold)</td>\n",
       "      <td id=\"T_740b5_row5_col1\" class=\"data row5 col1\" >{'max_depth': None, 'min_samples_leaf': 4, 'n_estimators': 100}</td>\n",
       "      <td id=\"T_740b5_row5_col2\" class=\"data row5 col2\" >0.6601</td>\n",
       "      <td id=\"T_740b5_row5_col3\" class=\"data row5 col3\" >0.6586</td>\n",
       "      <td id=\"T_740b5_row5_col4\" class=\"data row5 col4\" >0.6232</td>\n",
       "      <td id=\"T_740b5_row5_col5\" class=\"data row5 col5\" >0.8531</td>\n",
       "      <td id=\"T_740b5_row5_col6\" class=\"data row5 col6\" >4.3724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_740b5_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_740b5_row6_col0\" class=\"data row6 col0\" >SVM-Clf (Scaffold, k=1)</td>\n",
       "      <td id=\"T_740b5_row6_col1\" class=\"data row6 col1\" >{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td id=\"T_740b5_row6_col2\" class=\"data row6 col2\" >0.5616</td>\n",
       "      <td id=\"T_740b5_row6_col3\" class=\"data row6 col3\" >0.5596</td>\n",
       "      <td id=\"T_740b5_row6_col4\" class=\"data row6 col4\" >0.4771</td>\n",
       "      <td id=\"T_740b5_row6_col5\" class=\"data row6 col5\" >0.6788</td>\n",
       "      <td id=\"T_740b5_row6_col6\" class=\"data row6 col6\" >346.6144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_740b5_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_740b5_row7_col0\" class=\"data row7 col0\" >SVM-Clf (Scaffold, k=3)</td>\n",
       "      <td id=\"T_740b5_row7_col1\" class=\"data row7 col1\" >{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td id=\"T_740b5_row7_col2\" class=\"data row7 col2\" >0.6207</td>\n",
       "      <td id=\"T_740b5_row7_col3\" class=\"data row7 col3\" >0.6192</td>\n",
       "      <td id=\"T_740b5_row7_col4\" class=\"data row7 col4\" >0.5795</td>\n",
       "      <td id=\"T_740b5_row7_col5\" class=\"data row7 col5\" >0.7599</td>\n",
       "      <td id=\"T_740b5_row7_col6\" class=\"data row7 col6\" >416.6985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_740b5_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_740b5_row8_col0\" class=\"data row8 col0\" >SVM-Clf (Scaffold, k=5)</td>\n",
       "      <td id=\"T_740b5_row8_col1\" class=\"data row8 col1\" >{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td id=\"T_740b5_row8_col2\" class=\"data row8 col2\" >0.5714</td>\n",
       "      <td id=\"T_740b5_row8_col3\" class=\"data row8 col3\" >0.5694</td>\n",
       "      <td id=\"T_740b5_row8_col4\" class=\"data row8 col4\" >0.4839</td>\n",
       "      <td id=\"T_740b5_row8_col5\" class=\"data row8 col5\" >0.7595</td>\n",
       "      <td id=\"T_740b5_row8_col6\" class=\"data row8 col6\" >551.7917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26fce85dd60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nBACE Classification Results:\")\n",
    "display(style_results(df_classification, mode='classification'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c855c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification.to_csv('classification_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
